<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Improved New Object Reconstruction with Dynamic Gaussian Splatting</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                        <div class="author-block">
                          <a href="https://www.linkedin.com/in/ewa-miazga/" target="_blank">Ewa Miazga</a>
                        </div>
            </div>
            <div class="is-size-5 publication-authors">
                        <div class="author-block">
                          Supervisor: <a href="https://saqibjaved1.github.io" target="_blank">Saqib Javed</a>
                        </div>
            </div>

                        <div class="is-size-5 publication-authors">
                                <span class="author-block">EPFL<br>Research Project</span>
                        </div> 

              <!-- EPFL Logo -->
                        <div class="has-text-centered" style="margin-top: 1rem;">
                          <img src="new-results/epfllogo.png" alt="EPFL Logo" style="max-height: 100px;">
                        </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://github.com/ewaMiazga/improved-3dgstream/blob/main/CV_lab_Report-3.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ewaMiazga/improved-3dgstream" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-4 has-text-centered">Side-by-Side Comparison</h2>

    <div class="columns is-centered is-vcentered">
      <!-- Left Video -->
      <div class="column has-text-centered">
        <p><strong>Ours</strong></p>
        <video autoplay loop muted playsinline width="100%">
          <source src="teaser-videos/0.2-spawn500-dyn-color-spawn-300iter-new-loss-color-map-min-dist-1-col-mask.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <!-- Right Video -->
      <div class="column has-text-centered">
        <p><strong>3DGStream</strong></p>
        <video autoplay loop muted playsinline width="100%">
          <source src="teaser-videos/org-code-spawn1-iter300-0.00007.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Reconstruction of 3D scenes using multi-view cameras remains a significant challenge today. Training is often computationally expensive and does not always guarantee high-quality reconstructions. Furthermore, existing methods may not be suitable for all types of 3D scenes—such as indoor or outdoor environments with many dynamic objects. One notable limitation is the inability to reconstruct objects that emerge after the first frame. Methods like HiCoM and 3DG-Stream rely on a per-frame optimization strategy that is initialized from the first frame, making them unable to model objects that appear later in the sequence. In contrast, Dynamic 3D Gaussian Splatting adopts a frame-to-frame optimization approach, which allows for continuous updates and appears better suited for handling newly emerging elements in dynamic scenes. This work presents both qualitative and quantitative comparisons of the aforementioned methods, focusing on their ability to reconstruct newly appearing objects in dynamic 3D scenes. Additionally, it introduces an improved version of the 3DG-Stream method, which demonstrates the capability to reconstruct new objects more effectively.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Video carousel -->
<div class="columns is-multiline is-mobile">
  <div class="column is-one-fifth has-text-centered">
    <video src="teaser-videos/0.2-spawn500-dyn-color-spawn-300iter-new-loss-color-map-min-dist-1-col-mask.mp4" controls style="width: 100%; height: auto;"></video>
    <p class="video-title">Ours</p>
  </div>
  <div class="column is-one-fifth has-text-centered">
    <video src="teaser-videos/org-code-spawn1-iter300-0.00007.mp4" controls style="width: 100%; height: auto;"></video>
    <p class="video-title">3DGStream</p>
  </div>
  <div class="column is-one-fifth has-text-centered">
    <video src="carusel-videos/hicom.mp4" controls style="width: 100%; height: auto;"></video>
    <p class="video-title">HiCoM</p>
  </div>
  <div class="column is-one-fifth has-text-centered">
    <video src="carusel-videos/Dynamic3DGaussians.mp4" controls style="width: 100%; height: auto;"></video>
    <p class="video-title">Dynamic 3D Gaussians</p>
  </div>
  <div class="column is-one-fifth has-text-centered">
    <video src="carusel-videos/output_gt.mp4" controls style="width: 100%; height: auto;"></video>
    <p class="video-title">Ground Truth</p>
  </div>
</div>
<!-- End video carousel -->

<!-- Evaluation -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered">Evaluation</h2>

    <!-- Quantitative Evaluation -->
    <div class="content">
      <h3 class="title is-4">Quantitative Results</h3>
      <p class="is-size-6 mt-2">
        All three methods were trained on a dataset prepared according to the specifications outlined by the original authors. In most cases, this required separate processing for
        the first frame and subsequent frames.
        The reported PSNR values indicate that all three methods
        achieve similar reconstruction quality, consistent with the
        results presented in their respective papers.
        These results suggest that the majority of the scene was
        reconstructed successfully and with high fidelity. The
        HiCoM method achieves significantly lower storage requirements, highlighting a key improvement in efficiency
        compared to other approaches.
        Improved 3DG-Stream achieves only a slightly higher
        PSNR compared to the original version. Although the reconstruction of the phone is more detailed and visible in
        more frames than in the baseline, this improvement comes
        at a cost: for every new Gaussian added, one is removed. As
        a result, the method may under-reconstruct some uniform
        regions, ultimately balancing out the PSNR and failing to
        fully reflect the improved reconstruction quality. Furthermore, since the phone occupies only a small portion of the
        scene, its contribution to the overall PSNR metric is limited.
        HiCoM achieves the highest PSNR, likely due to its accurate reconstruction of static background regions that closely
        match the ground truth. However, a closer inspection reveals that the method introduces a significant amount of
        noise in areas corresponding to moving objects. This noise
        suggests poor handling of dynamic content, which is an undesirable characteristic of the algorithm despite its strong
        performance on static regions.
        It is worth noting that the training time for 3DG-Stream
        and HiCoM was significantly shorter - by a factor of approximately 6 - compared to Dynamic Gaussians, making
        them more efficient for practical use.
        </p>

        <p class="is-size-6 mt-2">
        3DG-Stream emphasizes the importance of undistorting
        subsequent camera frames. This process removes lens distortion from the input images and updates the associated
        camera parameters, resulting in a rectified version of the
        scene that is more suitable for geometric processing.
        To ensure a fair comparison, additional experiments were
        conducted on the undistorted version of the dataset to assess whether this preprocessing step benefits other methods.
        However, a significant improvement was observed only for
        3DG-Stream, which demonstrated a 39% performance increase. The results for the other methods remained within
        the standard deviation observed across multiple runs.
        </p>
      <div class="has-text-centered">
        <img src="new-results/eval-graphs.png" alt="Quantitative Evaluation Graph"
        style="width: 120%; height: auto; margin-top: 1rem;">
      </div>
    </div>

    <!-- Qualitative Evaluation -->
    <div class="content" style="margin-top: 3rem;">
      <h3 class="title is-4">Qualitative Results</h3>
      <p class="is-size-6 mt-2">
        Eventhough all the methods yield satisfactory results in
        terms of metrics, it is impossible to tell if our evaluation objective was met. To gain comprehensive insight into quality
        of new object reconstruction in the rendered frames from
        test camera.
        3DGStream The emerging object - a phone - fails to be
        reconstructed, indicating a shortcoming in Stage 2 of the
        optimization process, which is designed to account for new
        objects appearing in the scene. Stage 2 relies on detecting high view-space positional gradients to localize underreconstructed regions. However, in this case, the phone is
        small, blue in color, and partially blends with a green T-shirt
        background. Its motion is also minimal. These combined
        factors likely result in positional gradients that are too weak
        to surpass the threshold required for new Gaussian spawning. As a result, the model does not recognize this region as
        requiring additional representation.
                HiCoM Similar to 3DG-Stream, HiCoM also fails to reconstruct the phone. However, the underlying reasons
        are fundamentally different. The method does not incorporate any explicit mechanism for detecting or modeling
        newly emerging objects in the scene. Its Continual Refinement stage only densifies existing gaussians by dupli-
        cating or splitting them in regions identified as underrepresented—typically based on local rendering error. Since new
        gaussians can only be created through refinement of already
        existing ones, the model cannot represent objects that were
        entirely absent in the first frame. If no gaussians were initially placed in the region where the phone appears, there
        are no anchor points for refinement, and the phone cannot
        be reconstructed.
        The visual artifacts around moving individuals are likely
        due to limitations of the Coherent Motion model. The
        hierarchical motion estimation operates over spatial partitions and applies shared transformations, which may be
        too coarse to capture fine-grained, per - gaussian movements - especially those involving small or fast-moving
        body parts like limbs. This highlights a key limitation: although moving objects may occupy a small portion of the
        scene, they are perceptually dominant. A model focused on
        gradual, region-level motion may reconstruct static backgrounds well, but struggle to represent the subtle and complex dynamics of foreground motion, leading to unnatural
        blending or ghosting artifacts.
                Dynamic 3D Gaussians In contrast to the previous methods, Dynamic 3D Gaussians successfully reconstructs the
        phone, despite the authors stating that modeling newly
        emerging objects is a limitation of their approach. While
        no new Gaussians are introduced during the main training
        loop, an excess of them is generated during the densification step applied to the initial frame. The existing ones
        are allowed to move and rotate freely across frames. Unlike HiCoM, which applies motion in a coarse, region-based
        manner, Dynamic 3D Gaussians performs motion estimation at the level of individual gaussian. This flexibility enables some gaussians - originally associated with the T-shirt
        in the first frame - to be displaced toward the region where
        the phone appears.
        This behavior is guided by a combination of physically-inspired regularization losses: local rigidity, rotation consistency, and isometry. These priors ensure that gaussians
        move in a coherent and physically plausible manner while
        allowing sufficient flexibility to capture local deformations.
        Additionally, the phone’s color similarity to the surrounding T-shirt may have contributed to the reconstruction, as it
        allows nearby gaussians with similar appearance attributes
        to approximate the phone without requiring new gaussians
        to be added.
                To fully assess the limitations of Dynamic 3D Gaussians
        in modeling newly emerging objects, one would need to
        evaluate it on a dataset where a new object with distinct
        color and structure enters the scene - such that no similar
        gaussians exist nearby in the first frame. In such a scenario,
        it is likely that the method would struggle to reconstruct the
        object, just as 3DG-Stream and HiCoM do. This suggests
        that none of the examined methods provide a complete solution for handling new object emergence in dynamic 3D
        scenes.
        Improved 3DG-Stream The reconstruction of the new
        object is detailed and does not suffer from underreconstruction. However, one notable flaw is the flickering effect observed in the output video - the object is
        not consistently reconstructed in every frame. This issue
        arises because the difference maps used to identify underreconstructed regions are computed from a single view. If
        the object is occluded or not visible in that view, the corresponding region is not flagged for densification, and thus
        remains under-reconstructed. Conversely, when the object
        is visible, it is accurately reconstructed, demonstrating that
        the method behaves as intended when provided with the correct visibility cues.
        It is also worth noting that the dynamic spawning mechanism successfully prevents excessive Gaussian spawning
        in unrelated regions, effectively avoiding artifacts such
        as “flying Gaussians.” Nonetheless, the reliance on view-dependent evaluation remains a key limitation of this approach and should be further addressed in future work.
      </p>

      <div class="has-text-centered mb-5">
        <img src="new-results/cover-pic.png" alt="Qualitative Result 1"
             style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px;">
      </div>
      
      <div class="has-text-centered">
        <img src="new-results/qualitative-res.png" alt="Qualitative Result 2"
             style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px;">
      </div>

    </div>
  </div>
</section>
<!-- End Evaluation -->






<body>
  <style>
#results-carousel {
  display: flex !important;        /* force flex display */
  flex-wrap: nowrap;               /* keep items in one row */
  justify-content: center;         /* center horizontally */
  gap: 20px;                      /* space between items */
}

#results-carousel .item {
  flex: 0 0 auto;                 /* do not grow or shrink, keep size */
  text-align: center;
  width: 300px;                   /* fixed width for each item */
}

#results-carousel video {
  width: 100%;                   /* fill parent .item width */
  height: auto;
  border-radius: 6px;
}

    .carousel {
  width: 100%;
  overflow: hidden; /* hide horizontal overflow */
  position: relative;
}

.slider {
  outline: none; /* remove focus outline if desired */
}

.slider-container {
  display: flex;
  transition: transform 0.3s ease; /* smooth sliding */
  will-change: transform;
}

.slider-item {
  flex: 0 0 384px; /* fixed width */
  box-sizing: border-box;
  padding: 10px;
  text-align: center;
}

.slider-item video {
  width: 100%;
  height: auto;
  border-radius: 8px;
}

.slider-navigation-previous,
.slider-navigation-next {
  position: absolute;
  top: 50%;
  transform: translateY(-50%);
  cursor: pointer;
  width: 40px;
  height: 40px;
  color: #333;
  user-select: none;
}

.slider-navigation-previous {
  left: 10px;
}

.slider-navigation-next {
  right: 10px;
}


    </style>
</body>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            Website template credit to <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
